import os, datetime, subprocess, textwrap
from dotenv import load_dotenv
load_dotenv()                   # .env ì½ê¸°

import openai, yfinance as yf, matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
import ffmpeg                  # ffmpegâ€‘python ë˜í¼
import requests

# 1. ì£¼ê°€ì§€ìˆ˜ ë°ì´í„° ----------------------------------------------------------------
today   = datetime.datetime.now().date()
start   = today - datetime.timedelta(days=7)   # ìµœê·¼ 1ì£¼ì¼
ticker  = "^KS11"                              # KOSPI ì§€ìˆ˜ ê¸°í˜¸ (Yahoo Finance)
hist    = yf.download(ticker, start=start.isoformat(), end=today.isoformat())
if hist.empty:
    raise ValueError("ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ì „ì¼ ëŒ€ë¹„
if len(hist) < 2:
    raise ValueError("ìµœê·¼ 2ê±°ë˜ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (íœ´ì¥ì¼Â·ì£¼ë§ ë“±)")

prev_close  = hist["Close"].iloc[-2].item()
today_close = hist["Close"].iloc[-1].item()
chg_pct     = round((today_close - prev_close) / prev_close * 100, 2)
direction   = "ìƒìŠ¹" if chg_pct > 0 else "í•˜ë½"

# 2. GPT ìš”ì•½ ------------------------------------------------------------------------
openai.api_key = os.getenv("OPENAI_API_KEY")
prompt = textwrap.dedent(f"""
    ì˜¤ëŠ˜ KOSPI ì§€ìˆ˜ëŠ” ì „ì¼ ëŒ€ë¹„ {chg_pct}% {direction}í–ˆìŠµë‹ˆë‹¤.
    ì£¼ìš” ì›ì¸ê³¼ íˆ¬ììë“¤ì´ ì£¼ëª©í•  ë§Œí•œ í¬ì¸íŠ¸ë¥¼ 3ì¤„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    âŠ í•œê¸€ 30ì ì´ë‚´ë¡œ ê°„ê²° â‹ ìˆ«ìÂ·ê³ ìœ ëª…ì‚¬ ì •í™• âŒ ë§ë¯¸ì— ğŸ“Š ì´ëª¨ì§€ í•˜ë‚˜.
""").strip()

res = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role":"user","content":prompt}],
    max_tokens=120,
)
summary_txt = res.choices[0].message.content.strip()
print("GPT ìš”ì•½:\n", summary_txt)

# 3. ì°¨íŠ¸ PNG ------------------------------------------------------------------------
plt.figure(figsize=(6,3))
plt.plot(hist.index, hist["Close"], linewidth=2)
plt.title("KOSPI ìµœê·¼ 1ì£¼ì¼")
plt.tight_layout()
img_path = "chart.png"
plt.savefig(img_path, dpi=300)
plt.close()

# 4. ElevenLabs TTS ------------------------------------------------------------------
tts_api = os.getenv("ELEVEN_API_KEY")
voice_id = "21m00Tcm4TlvDq8ikWAM"     # ElevenLabs ê¸°ë³¸ í•œêµ­ì–´ ì—¬ì„± ìŒì„±
headers  = {"xi-api-key": tts_api}
payload  = {
    "text": summary_txt,
    "model_id": "eleven_monolingual_v1",
    "voice_settings": {"stability":0.4,"similarity_boost":0.7}
}
audio_path = "voice.wav"
r = requests.post(
    f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream",
    json=payload, headers=headers, stream=True, timeout=60,
)
with open(audio_path, "wb") as f:
    for chunk in r.iter_content(chunk_size=4096):
        f.write(chunk)

# 5. ffmpegë¡œ ì˜ìƒ í•©ì„± ---------------------------------------------------------------
video_path = "output.mp4"
# (a) ì°¨íŠ¸ ì´ë¯¸ì§€ 10ì´ˆ ê³ ì •
input_stream = ffmpeg.input(img_path, loop=1, t=10, framerate=30)
# (b) ì˜¤ë””ì˜¤ íŠ¸ë™ ì‚½ì…
audio_stream = ffmpeg.input(audio_path)
(
    ffmpeg
    .output(input_stream, audio_stream, video_path,
            vcodec="libx264", acodec="aac",
            pix_fmt="yuv420p", shortest=None, loglevel="error")
    .overwrite_output()
    .run()
)
print(f"\nğŸ¬Â ì™„ë£Œ!  {video_path} ìƒì„±")